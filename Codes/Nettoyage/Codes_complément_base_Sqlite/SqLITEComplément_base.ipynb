{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id             nom  date_ouverture  date_fermeture                 website  \\\n",
      "0  71         La loge            2012             NaN          www.la-loge.be   \n",
      "1   8  Jeune création            2006             NaN                     NaN   \n",
      "2  72       The ister            2011             NaN         www.theister.be   \n",
      "3  73         Komplot            2002             NaN            www.kmplt.be   \n",
      "4  74         Abilene            2011             NaN  www.abilenegallery.com   \n",
      "\n",
      "                        email                             adresse horaires  \\\n",
      "0             info@la-loge.be  Kluisstraat - rue de l’Ermitage 86      NaN   \n",
      "1     jeunecreation@gmail.com                       24 rue Berthe      NaN   \n",
      "2            info@theister.be                rue Vandenbranden 42      NaN   \n",
      "3               info@kmplt.be           295 Avenue Van Volxemlaan      NaN   \n",
      "4  contact@abilenegallery.com              Rue de la Victoire 163      NaN   \n",
      "\n",
      "  presentation responsables  ...            slug      pays      ville  \\\n",
      "0          NaN          NaN  ...         la-loge  Belgique  Bruxelles   \n",
      "1          NaN          NaN  ...  jeune-creation    France      Paris   \n",
      "2          NaN          NaN  ...       the-ister  Belgique  Bruxelles   \n",
      "3          NaN          NaN  ...         komplot  Belgique  Bruxelles   \n",
      "4          NaN          NaN  ...         abilene  Belgique  Bruxelles   \n",
      "\n",
      "    latitude longitude                                   adresse_complete  \\\n",
      "0  50.828460  4.365647  Kluisstraat - rue de l’Ermitage 86, 1050, Brux...   \n",
      "1  48.885626  2.339779                24 rue Berthe, 75018, Paris, France   \n",
      "2  50.851027  4.340663    rue Vandenbranden 42, 1000, Bruxelles, Belgique   \n",
      "3  50.821609  4.325936  295 Avenue Van Volxemlaan, 1190, Bruxelles, Be...   \n",
      "4  50.827174  4.352473  Rue de la Victoire 163, 1060, Bruxelles, Belgique   \n",
      "\n",
      "  codepostal telephone visite user_id  \n",
      "0     1050.0       NaN    NaN     NaN  \n",
      "1    75018.0       NaN    NaN     1.0  \n",
      "2     1000.0       NaN    NaN     NaN  \n",
      "3     1190.0       NaN    NaN     NaN  \n",
      "4     1060.0       NaN    NaN     NaN  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_excel('../../../Donnees/spacestri.xlsx')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at 'réponses-ARS-Carré-dart-sans-mise-en-forme.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Utilisation\u001b[39;00m\n\u001b[0;32m     35\u001b[0m chemin_docx \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mréponses-ARS-Carré-dart-sans-mise-en-forme.docx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 36\u001b[0m donnees_extraites \u001b[38;5;241m=\u001b[39m \u001b[43mextraire_donnees_depuis_docx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchemin_docx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Charger le fichier Excel avec pandas\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../Donnees/spacestri.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mextraire_donnees_depuis_docx\u001b[1;34m(chemin_docx)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextraire_donnees_depuis_docx\u001b[39m(chemin_docx):\n\u001b[1;32m----> 5\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[43mdocx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchemin_docx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     donnees \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m     nom_actuel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\docx\\api.py:27\u001b[0m, in \u001b[0;36mDocument\u001b[1;34m(docx)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a |Document| object loaded from `docx`, where `docx` can be either a path\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03mto a ``.docx`` file (a string) or a file-like object.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03mIf `docx` is missing or ``None``, the built-in default document \"template\" is\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mloaded.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m docx \u001b[38;5;241m=\u001b[39m _default_docx_path() \u001b[38;5;28;01mif\u001b[39;00m docx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m docx\n\u001b[1;32m---> 27\u001b[0m document_part \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentPart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mPackage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmain_document_part)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m document_part\u001b[38;5;241m.\u001b[39mcontent_type \u001b[38;5;241m!=\u001b[39m CT\u001b[38;5;241m.\u001b[39mWML_DOCUMENT_MAIN:\n\u001b[0;32m     29\u001b[0m     tmpl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a Word file, content type is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\docx\\opc\\package.py:127\u001b[0m, in \u001b[0;36mOpcPackage.open\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pkg_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OpcPackage:\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an |OpcPackage| instance loaded with the contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     pkg_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPackageReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     package \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m    129\u001b[0m     Unmarshaller\u001b[38;5;241m.\u001b[39munmarshal(pkg_reader, package, PartFactory)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\docx\\opc\\pkgreader.py:22\u001b[0m, in \u001b[0;36mPackageReader.from_file\u001b[1;34m(pkg_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_file\u001b[39m(pkg_file):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a |PackageReader| instance loaded with contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     phys_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPhysPkgReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     content_types \u001b[38;5;241m=\u001b[39m _ContentTypeMap\u001b[38;5;241m.\u001b[39mfrom_xml(phys_reader\u001b[38;5;241m.\u001b[39mcontent_types_xml)\n\u001b[0;32m     24\u001b[0m     pkg_srels \u001b[38;5;241m=\u001b[39m PackageReader\u001b[38;5;241m.\u001b[39m_srels_for(phys_reader, PACKAGE_URI)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\docx\\opc\\phys_pkg.py:21\u001b[0m, in \u001b[0;36mPhysPkgReader.__new__\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m         reader_cls \u001b[38;5;241m=\u001b[39m _ZipPkgReader\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPackage not found at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m pkg_file)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume it's a stream and pass it to Zip reader to sort out\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reader_cls \u001b[38;5;241m=\u001b[39m _ZipPkgReader\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: Package not found at 'réponses-ARS-Carré-dart-sans-mise-en-forme.docx'"
     ]
    }
   ],
   "source": [
    "import docx  # python-docx est importé en tant que 'docx'\n",
    "import pandas as pd\n",
    "\n",
    "def extraire_donnees_depuis_docx(chemin_docx):\n",
    "    document = docx.Document(chemin_docx)\n",
    "    \n",
    "    donnees = []\n",
    "    nom_actuel = None\n",
    "    question_actuelle = None\n",
    "    questions_reponses = {}\n",
    "    \n",
    "    for paragraphe in document.paragraphs:\n",
    "        texte = paragraphe.text.strip()\n",
    "        \n",
    "        if paragraphe.style.name.startswith('Heading'):  # Suppose que le nom est un titre\n",
    "            if nom_actuel and questions_reponses:\n",
    "                donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "            nom_actuel = texte\n",
    "            questions_reponses = {}\n",
    "            question_actuelle = None\n",
    "        \n",
    "        elif texte.startswith(\"Q\"):  \n",
    "            question_actuelle = texte\n",
    "            questions_reponses[question_actuelle] = ''\n",
    "        \n",
    "        elif question_actuelle:  # Suppose que tout texte après une question est une réponse\n",
    "            questions_reponses[question_actuelle] += ' ' + texte\n",
    "    \n",
    "    if nom_actuel and questions_reponses:\n",
    "        donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "    \n",
    "    return donnees\n",
    "\n",
    "# Utilisation\n",
    "chemin_docx = 'réponses-ARS-Carré-dart-sans-mise-en-forme.docx'\n",
    "donnees_extraites = extraire_donnees_depuis_docx(chemin_docx)\n",
    "\n",
    "# Charger le fichier Excel avec pandas\n",
    "df = pd.read_excel('../../../Donnees/spacestri.xlsx')\n",
    "\n",
    "# Ajouter les colonnes pour les questions et réponses dans le DataFrame\n",
    "df['question1'] = ''\n",
    "df['réponse1'] = ''\n",
    "df['question2'] = ''\n",
    "df['réponse2'] = ''\n",
    "\n",
    "# Vérifier la dernière valeur d'ID dans le DataFrame\n",
    "dernier_id = df['id'].max() if 'id' in df.columns else 0  # Si la colonne 'id' existe, on prend sa valeur max, sinon on commence à 0\n",
    "\n",
    "\n",
    "# Parcourir les données extraites du DOCX\n",
    "for entree in donnees_extraites:\n",
    "    nom = entree['nom']\n",
    "    questions = list(entree['questions_reponses'].keys())\n",
    "    reponses = list(entree['questions_reponses'].values())\n",
    "    \n",
    "    # Si le nom est dans le DataFrame, on remplit les colonnes correspondantes\n",
    "    if nom in df['nom'].values:\n",
    "        df.loc[df['nom'] == nom, 'question1'] = questions[0] if len(questions) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse1'] = reponses[0] if len(reponses) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'question2'] = questions[1] if len(questions) > 1 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse2'] = reponses[1] if len(reponses) > 1 else ''\n",
    "    \n",
    "    # Si le nom n'est pas dans le DataFrame, on ajoute une nouvelle ligne\n",
    "    else:\n",
    "        dernier_id +=1 \n",
    "        nouvelle_ligne = pd.DataFrame({\n",
    "            'id': [dernier_id],\n",
    "            'nom': [nom],\n",
    "            'question1': [questions[0] if len(questions) > 0 else ''],\n",
    "            'réponse1': [reponses[0] if len(reponses) > 0 else ''],\n",
    "            'question2': [questions[1] if len(questions) > 1 else ''],\n",
    "            'réponse2': [reponses[1] if len(reponses) > 1 else '']\n",
    "        })\n",
    "        df = pd.concat([df, nouvelle_ligne], ignore_index=True)\n",
    "\n",
    "# Sauvegarder le DataFrame mis à jour dans un fichier Excel ou CSV\n",
    "df.to_excel('fichier_mis_a_jour.xlsx', index=False)\n",
    "print(\"Mise à jour du fichier Excel terminée et sauvegardée dans 'fichier_mis_a_jour.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'donnees_extraites' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nom_responsable, sites_web\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Parcourir les données extraites du DOCX\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entree \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdonnees_extraites\u001b[49m:\n\u001b[0;32m     49\u001b[0m     nom \u001b[38;5;241m=\u001b[39m entree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     50\u001b[0m     questions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(entree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_reponses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'donnees_extraites' is not defined"
     ]
    }
   ],
   "source": [
    "import docx  # python-docx est importé en tant que 'docx'\n",
    "import pandas as pd\n",
    "import re  # Pour utiliser les expressions régulières\n",
    "\n",
    "def extraire_donnees_depuis_docx(chemin_docx):\n",
    "    document = docx.Document(chemin_docx)\n",
    "    \n",
    "    donnees = []\n",
    "    nom_actuel = None\n",
    "    question_actuelle = None\n",
    "    questions_reponses = {}\n",
    "    \n",
    "    for paragraphe in document.paragraphs:\n",
    "        texte = paragraphe.text.strip()\n",
    "        \n",
    "        if paragraphe.style.name.startswith('Heading'):  # Suppose que le nom est un titre\n",
    "            if nom_actuel and questions_reponses:\n",
    "                donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "            nom_actuel = texte\n",
    "            questions_reponses = {}\n",
    "            question_actuelle = None\n",
    "        \n",
    "        elif texte.startswith(\"Q\"):  # Suppose que les questions commencent par \"Q\"\n",
    "            question_actuelle = texte\n",
    "            questions_reponses[question_actuelle] = ''\n",
    "        \n",
    "        elif question_actuelle:  # Suppose que tout texte après une question est une réponse\n",
    "            questions_reponses[question_actuelle] += ' ' + texte\n",
    "    \n",
    "    if nom_actuel and questions_reponses:\n",
    "        donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "    \n",
    "    return donnees\n",
    "\n",
    "def extraire_nom_et_sites(texte):\n",
    "    # Regex améliorée pour capturer des noms composés et gérer mieux les titres\n",
    "    match_nom = re.search(r'([A-Z][a-zéèêîï]+(?:\\s[A-Z][a-zéèêîï]+)+)', texte)\n",
    "    nom_responsable = match_nom.group(0) if match_nom else 'Nom non trouvé'\n",
    "    \n",
    "    # Regex pour capturer tous les sites web dans le texte (peut en avoir plusieurs)\n",
    "    sites_web = re.findall(r'(www\\.[\\w.-]+|@\\w+)', texte)\n",
    "    if not sites_web:\n",
    "        sites_web = ['Site web non trouvé']\n",
    "    \n",
    "    return nom_responsable, sites_web\n",
    "\n",
    "# Parcourir les données extraites du DOCX\n",
    "for entree in donnees_extraites:\n",
    "    nom = entree['nom']\n",
    "    questions = list(entree['questions_reponses'].keys())\n",
    "    reponses = list(entree['questions_reponses'].values())\n",
    "    \n",
    "    # Si le nom est dans le DataFrame, on remplit les colonnes correspondantes\n",
    "    if nom in df['nom'].values:\n",
    "        df.loc[df['nom'] == nom, 'question1'] = questions[0] if len(questions) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse1'] = reponses[0] if len(reponses) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'question2'] = questions[1] if len(questions) > 1 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse2'] = reponses[1] if len(reponses) > 1 else ''\n",
    "        \n",
    "        # Extraire le nom du responsable et les sites web à partir de la réponse 2\n",
    "        nom_responsable, sites_web = extraire_nom_et_sites(reponses[1] if len(reponses) > 1 else '')\n",
    "        \n",
    "        # Afficher pour vérification\n",
    "        print(f\"Nom : {nom}\")\n",
    "        print(f\"Nom du responsable : {nom_responsable}\")\n",
    "        print(f\"Sites web : {', '.join(sites_web)}\\n\")\n",
    "        \n",
    "        df.loc[df['nom'] == nom, 'nom_responsable'] = nom_responsable\n",
    "        df.loc[df['nom'] == nom, 'site_web'] = ', '.join(sites_web)\n",
    "    \n",
    "    # Si le nom n'est pas dans le DataFrame, on ajoute une nouvelle ligne\n",
    "    else:\n",
    "        nom_responsable, sites_web = extraire_nom_et_sites(reponses[1] if len(reponses) > 1 else '')\n",
    "        \n",
    "        # Afficher pour vérification\n",
    "        print(f\"Nom : {nom}\")\n",
    "        print(f\"Nom du responsable : {nom_responsable}\")\n",
    "        print(f\"Sites web : {', '.join(sites_web)}\\n\")\n",
    "        \n",
    "        nouvelle_ligne = pd.DataFrame({\n",
    "            'nom': [nom],\n",
    "            'question1': [questions[0] if len(questions) > 0 else ''],\n",
    "            'réponse1': [reponses[0] if len(reponses) > 0 else ''],\n",
    "            'question2': [questions[1] if len(questions) > 1 else ''],\n",
    "            'réponse2': [reponses[1] if len(reponses) > 1 else ''],\n",
    "            'nom_responsable': [nom_responsable],\n",
    "            'site_web': [', '.join(sites_web)]\n",
    "        })\n",
    "        df = pd.concat([df, nouvelle_ligne], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier excel\n",
    "df= pd.read_excel('fichier_mis_a_jour.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "\n",
    "# Exemple de filtrage\n",
    "#filtered_df = df[df['colonne'] == 'valeur']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'nom', 'date_ouverture', 'date_fermeture', 'website', 'email',\n",
      "       'adresse', 'horaires', 'presentation', 'responsables', 'historique',\n",
      "       'activites', 'expositions', 'publications', 'events', 'residences',\n",
      "       'workshop', 'archive', 'librairie', 'coworking', 'education',\n",
      "       'nb_expos_an', 'nb_artistes_an', 'partenaires', 'created_at',\n",
      "       'updated_at', 'slug', 'pays', 'ville', 'latitude', 'longitude',\n",
      "       'adresse_complete', 'codepostal', 'telephone', 'visite', 'user_id',\n",
      "       'question1', 'réponse1', 'question2', 'réponse2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes dans 'id' : 4\n"
     ]
    }
   ],
   "source": [
    "df_selection1 = df[['id', 'nom', 'historique', 'activites', 'presentation', \n",
    "                    'date_ouverture', 'date_fermeture', 'website', 'pays', \n",
    "                    'ville', 'latitude', 'longitude']]\n",
    "# Vérifier le nombre de valeurs manquantes dans la colonne 'id'\n",
    "missing_values_count = df_selection1['id'].isnull().sum()\n",
    "print(f\"Nombre de valeurs manquantes dans 'id' : {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs uniques dans la colonne 'id'\n",
    "duplicates = df_selection1['id'][df_selection1['id'].duplicated(keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Les identifiants suivants sont en double :\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"Tous les identifiants sont uniques.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Insérer les données dans la table 'Espace'\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df_selection1\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 71\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m    INSERT INTO Espace (id_E, nom, historique, activites, presentation, \u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124m                        date_ouverture, date_fermeture, website, pays, \u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m                        ville, latitude, longitude) \u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m, (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorique\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivites\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresentation\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     77\u001b[0m           row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_ouverture\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_fermeture\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpays\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     78\u001b[0m           row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mville\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Effectuer un commit tous les 100 enregistrements\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel dans un DataFrame\n",
    "df = pd.read_excel('fichier_mis_a_jour.xlsx')\n",
    "\n",
    "# Sélectionner certaines colonnes du DataFrame\n",
    "df_selection1 = df[['id', 'nom', 'historique', 'activites', 'presentation', \n",
    "                    'date_ouverture', 'date_fermeture', 'website', 'pays', \n",
    "                    'ville', 'latitude', 'longitude']]\n",
    "\n",
    "df_selection2 = df[['id', 'responsables']]\n",
    "df_selection3 = df[['id', 'question1', 'réponse1', 'question2', 'réponse2']]\n",
    "\n",
    "# Créer/établir une connexion à une base de données SQLite\n",
    "with sqlite3.connect('spacestri.db', timeout=10) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "# Créer la table Question_Reponse\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Question_Reponse (\n",
    "    id_QR INTEGER PRIMARY KEY,\n",
    "    question1 TEXT,\n",
    "    reponse1 TEXT,\n",
    "    question2 TEXT,\n",
    "    reponse2 TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table Responsable\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Responsable (\n",
    "    id_R INTEGER PRIMARY KEY,\n",
    "    responsables TEXT,\n",
    "    id_QReponse INTEGER,         \n",
    "    FOREIGN KEY (id_QReponse) REFERENCES Question_Reponse (id_QR)         \n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table Espace\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Espace (\n",
    "    id_E INTEGER PRIMARY KEY,\n",
    "    nom TEXT,\n",
    "    historique TEXT,\n",
    "    activites TEXT,\n",
    "    presentation TEXT,\n",
    "    date_ouverture DATE,\n",
    "    date_fermeture DATE,\n",
    "    website TEXT,\n",
    "    pays TEXT,\n",
    "    ville TEXT,\n",
    "    latitude TEXT,\n",
    "    longitude TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table de liaison 'tenir' pour relier Espace et Responsable\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS tenir (\n",
    "    id_tenir INTEGER PRIMARY KEY,\n",
    "    id_espace INTEGER,\n",
    "    id_responsable INTEGER,\n",
    "    FOREIGN KEY (id_espace) REFERENCES Espace(id_E),\n",
    "    FOREIGN KEY (id_responsable) REFERENCES Responsable(id_R)\n",
    ");\n",
    "''')\n",
    "\n",
    "# Insérer les données dans la table 'Espace'\n",
    "for i, row in df_selection1.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Espace (id_E, nom, historique, activites, presentation, \n",
    "                        date_ouverture, date_fermeture, website, pays, \n",
    "                        ville, latitude, longitude) \n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (row['id'], row['nom'], row['historique'], row['activites'], row['presentation'], \n",
    "          row['date_ouverture'], row['date_fermeture'], row['website'], row['pays'], \n",
    "          row['ville'], row['latitude'], row['longitude']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# N'oubliez pas de faire un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Insérer les données dans la table 'Question_Reponse'\n",
    "for i, row in df_selection3.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Question_Reponse (id_QR, question1, reponse1, question2, reponse2)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['id'], row['question1'], row['réponse1'], row['question2'], row['réponse2']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Insérer les données dans la table 'Responsable'\n",
    "for i, row in df_selection2.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Responsable (id_R, responsables, id_QReponse)\n",
    "    VALUES (?, ?, ?)\n",
    "    ''', (row['id'], row['responsables'], row['id']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "id_tenir = 1  # Initialiser un compteur pour id_tenir\n",
    "\n",
    "for i, row in df_selection1.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO tenir (id_tenir, id_espace, id_responsable)\n",
    "    VALUES (?, ?, ?)\n",
    "    ''', (id_tenir, row['id'], row['id']))  # Utiliser l'id_tenir incrémenté\n",
    "\n",
    "    id_tenir += 1  # Incrémenter l'ID pour la prochaine ligne\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Sauvegarder (commit) les changements\n",
    "conn.commit()\n",
    "\n",
    "# Fermer la connexion à la base de données\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
