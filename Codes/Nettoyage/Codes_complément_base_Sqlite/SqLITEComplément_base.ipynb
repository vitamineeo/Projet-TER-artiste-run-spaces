{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('spacestri.xlsx')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mise à jour du fichier Excel terminée et sauvegardée dans 'fichier_mis_a_jour.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import docx  # python-docx est importé en tant que 'docx'\n",
    "import pandas as pd\n",
    "\n",
    "def extraire_donnees_depuis_docx(chemin_docx):\n",
    "    document = docx.Document(chemin_docx)\n",
    "    \n",
    "    donnees = []\n",
    "    nom_actuel = None\n",
    "    question_actuelle = None\n",
    "    questions_reponses = {}\n",
    "    \n",
    "    for paragraphe in document.paragraphs:\n",
    "        texte = paragraphe.text.strip()\n",
    "        \n",
    "        if paragraphe.style.name.startswith('Heading'):  # Suppose que le nom est un titre\n",
    "            if nom_actuel and questions_reponses:\n",
    "                donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "            nom_actuel = texte\n",
    "            questions_reponses = {}\n",
    "            question_actuelle = None\n",
    "        \n",
    "        elif texte.startswith(\"Q\"):  \n",
    "            question_actuelle = texte\n",
    "            questions_reponses[question_actuelle] = ''\n",
    "        \n",
    "        elif question_actuelle:  # Suppose que tout texte après une question est une réponse\n",
    "            questions_reponses[question_actuelle] += ' ' + texte\n",
    "    \n",
    "    if nom_actuel and questions_reponses:\n",
    "        donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "    \n",
    "    return donnees\n",
    "\n",
    "# Utilisation\n",
    "chemin_docx = 'réponses-ARS-Carré-dart-sans mise en fome.docx'\n",
    "donnees_extraites = extraire_donnees_depuis_docx(chemin_docx)\n",
    "\n",
    "# Charger le fichier Excel avec pandas\n",
    "df = pd.read_excel('spacestri.xlsx')\n",
    "\n",
    "# Ajouter les colonnes pour les questions et réponses dans le DataFrame\n",
    "df['question1'] = ''\n",
    "df['réponse1'] = ''\n",
    "df['question2'] = ''\n",
    "df['réponse2'] = ''\n",
    "\n",
    "# Vérifier la dernière valeur d'ID dans le DataFrame\n",
    "dernier_id = df['id'].max() if 'id' in df.columns else 0  # Si la colonne 'id' existe, on prend sa valeur max, sinon on commence à 0\n",
    "\n",
    "\n",
    "# Parcourir les données extraites du DOCX\n",
    "for entree in donnees_extraites:\n",
    "    nom = entree['nom']\n",
    "    questions = list(entree['questions_reponses'].keys())\n",
    "    reponses = list(entree['questions_reponses'].values())\n",
    "    \n",
    "    # Si le nom est dans le DataFrame, on remplit les colonnes correspondantes\n",
    "    if nom in df['nom'].values:\n",
    "        df.loc[df['nom'] == nom, 'question1'] = questions[0] if len(questions) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse1'] = reponses[0] if len(reponses) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'question2'] = questions[1] if len(questions) > 1 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse2'] = reponses[1] if len(reponses) > 1 else ''\n",
    "    \n",
    "    # Si le nom n'est pas dans le DataFrame, on ajoute une nouvelle ligne\n",
    "    else:\n",
    "        dernier_id +=1 \n",
    "        nouvelle_ligne = pd.DataFrame({\n",
    "            'id': [dernier_id],\n",
    "            'nom': [nom],\n",
    "            'question1': [questions[0] if len(questions) > 0 else ''],\n",
    "            'réponse1': [reponses[0] if len(reponses) > 0 else ''],\n",
    "            'question2': [questions[1] if len(questions) > 1 else ''],\n",
    "            'réponse2': [reponses[1] if len(reponses) > 1 else '']\n",
    "        })\n",
    "        df = pd.concat([df, nouvelle_ligne], ignore_index=True)\n",
    "\n",
    "# Sauvegarder le DataFrame mis à jour dans un fichier Excel ou CSV\n",
    "df.to_excel('fichier_mis_a_jour.xlsx', index=False)\n",
    "print(\"Mise à jour du fichier Excel terminée et sauvegardée dans 'fichier_mis_a_jour.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx  # python-docx est importé en tant que 'docx'\n",
    "import pandas as pd\n",
    "import re  # Pour utiliser les expressions régulières\n",
    "\n",
    "def extraire_donnees_depuis_docx(chemin_docx):\n",
    "    document = docx.Document(chemin_docx)\n",
    "    \n",
    "    donnees = []\n",
    "    nom_actuel = None\n",
    "    question_actuelle = None\n",
    "    questions_reponses = {}\n",
    "    \n",
    "    for paragraphe in document.paragraphs:\n",
    "        texte = paragraphe.text.strip()\n",
    "        \n",
    "        if paragraphe.style.name.startswith('Heading'):  # Suppose que le nom est un titre\n",
    "            if nom_actuel and questions_reponses:\n",
    "                donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "            nom_actuel = texte\n",
    "            questions_reponses = {}\n",
    "            question_actuelle = None\n",
    "        \n",
    "        elif texte.startswith(\"Q\"):  # Suppose que les questions commencent par \"Q\"\n",
    "            question_actuelle = texte\n",
    "            questions_reponses[question_actuelle] = ''\n",
    "        \n",
    "        elif question_actuelle:  # Suppose que tout texte après une question est une réponse\n",
    "            questions_reponses[question_actuelle] += ' ' + texte\n",
    "    \n",
    "    if nom_actuel and questions_reponses:\n",
    "        donnees.append({'nom': nom_actuel, 'questions_reponses': questions_reponses})\n",
    "    \n",
    "    return donnees\n",
    "\n",
    "def extraire_nom_et_sites(texte):\n",
    "    # Regex améliorée pour capturer des noms composés et gérer mieux les titres\n",
    "    match_nom = re.search(r'([A-Z][a-zéèêîï]+(?:\\s[A-Z][a-zéèêîï]+)+)', texte)\n",
    "    nom_responsable = match_nom.group(0) if match_nom else 'Nom non trouvé'\n",
    "    \n",
    "    # Regex pour capturer tous les sites web dans le texte (peut en avoir plusieurs)\n",
    "    sites_web = re.findall(r'(www\\.[\\w.-]+|@\\w+)', texte)\n",
    "    if not sites_web:\n",
    "        sites_web = ['Site web non trouvé']\n",
    "    \n",
    "    return nom_responsable, sites_web\n",
    "\n",
    "# Parcourir les données extraites du DOCX\n",
    "for entree in donnees_extraites:\n",
    "    nom = entree['nom']\n",
    "    questions = list(entree['questions_reponses'].keys())\n",
    "    reponses = list(entree['questions_reponses'].values())\n",
    "    \n",
    "    # Si le nom est dans le DataFrame, on remplit les colonnes correspondantes\n",
    "    if nom in df['nom'].values:\n",
    "        df.loc[df['nom'] == nom, 'question1'] = questions[0] if len(questions) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse1'] = reponses[0] if len(reponses) > 0 else ''\n",
    "        df.loc[df['nom'] == nom, 'question2'] = questions[1] if len(questions) > 1 else ''\n",
    "        df.loc[df['nom'] == nom, 'réponse2'] = reponses[1] if len(reponses) > 1 else ''\n",
    "        \n",
    "        # Extraire le nom du responsable et les sites web à partir de la réponse 2\n",
    "        nom_responsable, sites_web = extraire_nom_et_sites(reponses[1] if len(reponses) > 1 else '')\n",
    "        \n",
    "        # Afficher pour vérification\n",
    "        print(f\"Nom : {nom}\")\n",
    "        print(f\"Nom du responsable : {nom_responsable}\")\n",
    "        print(f\"Sites web : {', '.join(sites_web)}\\n\")\n",
    "        \n",
    "        df.loc[df['nom'] == nom, 'nom_responsable'] = nom_responsable\n",
    "        df.loc[df['nom'] == nom, 'site_web'] = ', '.join(sites_web)\n",
    "    \n",
    "    # Si le nom n'est pas dans le DataFrame, on ajoute une nouvelle ligne\n",
    "    else:\n",
    "        nom_responsable, sites_web = extraire_nom_et_sites(reponses[1] if len(reponses) > 1 else '')\n",
    "        \n",
    "        # Afficher pour vérification\n",
    "        print(f\"Nom : {nom}\")\n",
    "        print(f\"Nom du responsable : {nom_responsable}\")\n",
    "        print(f\"Sites web : {', '.join(sites_web)}\\n\")\n",
    "        \n",
    "        nouvelle_ligne = pd.DataFrame({\n",
    "            'nom': [nom],\n",
    "            'question1': [questions[0] if len(questions) > 0 else ''],\n",
    "            'réponse1': [reponses[0] if len(reponses) > 0 else ''],\n",
    "            'question2': [questions[1] if len(questions) > 1 else ''],\n",
    "            'réponse2': [reponses[1] if len(reponses) > 1 else ''],\n",
    "            'nom_responsable': [nom_responsable],\n",
    "            'site_web': [', '.join(sites_web)]\n",
    "        })\n",
    "        df = pd.concat([df, nouvelle_ligne], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier excel\n",
    "df= pd.read_excel('fichier_mis_a_jour.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "\n",
    "# Exemple de filtrage\n",
    "#filtered_df = df[df['colonne'] == 'valeur']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'nom', 'date_ouverture', 'date_fermeture', 'website', 'email',\n",
      "       'adresse', 'horaires', 'presentation', 'responsables', 'historique',\n",
      "       'activites', 'expositions', 'publications', 'events', 'residences',\n",
      "       'workshop', 'archive', 'librairie', 'coworking', 'education',\n",
      "       'nb_expos_an', 'nb_artistes_an', 'partenaires', 'created_at',\n",
      "       'updated_at', 'slug', 'pays', 'ville', 'latitude', 'longitude',\n",
      "       'adresse_complete', 'codepostal', 'telephone', 'visite', 'user_id',\n",
      "       'question1', 'réponse1', 'question2', 'réponse2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes dans 'id' : 4\n"
     ]
    }
   ],
   "source": [
    "df_selection1 = df[['id', 'nom', 'historique', 'activites', 'presentation', \n",
    "                    'date_ouverture', 'date_fermeture', 'website', 'pays', \n",
    "                    'ville', 'latitude', 'longitude']]\n",
    "# Vérifier le nombre de valeurs manquantes dans la colonne 'id'\n",
    "missing_values_count = df_selection1['id'].isnull().sum()\n",
    "print(f\"Nombre de valeurs manquantes dans 'id' : {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs uniques dans la colonne 'id'\n",
    "duplicates = df_selection1['id'][df_selection1['id'].duplicated(keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Les identifiants suivants sont en double :\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"Tous les identifiants sont uniques.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Insérer les données dans la table 'Espace'\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df_selection1\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 71\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m    INSERT INTO Espace (id_E, nom, historique, activites, presentation, \u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124m                        date_ouverture, date_fermeture, website, pays, \u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m                        ville, latitude, longitude) \u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m, (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorique\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivites\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresentation\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     77\u001b[0m           row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_ouverture\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_fermeture\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpays\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     78\u001b[0m           row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mville\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Effectuer un commit tous les 100 enregistrements\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel dans un DataFrame\n",
    "df = pd.read_excel('fichier_mis_a_jour.xlsx')\n",
    "\n",
    "# Sélectionner certaines colonnes du DataFrame\n",
    "df_selection1 = df[['id', 'nom', 'historique', 'activites', 'presentation', \n",
    "                    'date_ouverture', 'date_fermeture', 'website', 'pays', \n",
    "                    'ville', 'latitude', 'longitude']]\n",
    "\n",
    "df_selection2 = df[['id', 'responsables']]\n",
    "df_selection3 = df[['id', 'question1', 'réponse1', 'question2', 'réponse2']]\n",
    "\n",
    "# Créer/établir une connexion à une base de données SQLite\n",
    "with sqlite3.connect('spacestri.db', timeout=10) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "# Créer la table Question_Reponse\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Question_Reponse (\n",
    "    id_QR INTEGER PRIMARY KEY,\n",
    "    question1 TEXT,\n",
    "    reponse1 TEXT,\n",
    "    question2 TEXT,\n",
    "    reponse2 TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table Responsable\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Responsable (\n",
    "    id_R INTEGER PRIMARY KEY,\n",
    "    responsables TEXT,\n",
    "    id_QReponse INTEGER,         \n",
    "    FOREIGN KEY (id_QReponse) REFERENCES Question_Reponse (id_QR)         \n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table Espace\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Espace (\n",
    "    id_E INTEGER PRIMARY KEY,\n",
    "    nom TEXT,\n",
    "    historique TEXT,\n",
    "    activites TEXT,\n",
    "    presentation TEXT,\n",
    "    date_ouverture DATE,\n",
    "    date_fermeture DATE,\n",
    "    website TEXT,\n",
    "    pays TEXT,\n",
    "    ville TEXT,\n",
    "    latitude TEXT,\n",
    "    longitude TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "# Créer la table de liaison 'tenir' pour relier Espace et Responsable\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS tenir (\n",
    "    id_tenir INTEGER PRIMARY KEY,\n",
    "    id_espace INTEGER,\n",
    "    id_responsable INTEGER,\n",
    "    FOREIGN KEY (id_espace) REFERENCES Espace(id_E),\n",
    "    FOREIGN KEY (id_responsable) REFERENCES Responsable(id_R)\n",
    ");\n",
    "''')\n",
    "\n",
    "# Insérer les données dans la table 'Espace'\n",
    "for i, row in df_selection1.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Espace (id_E, nom, historique, activites, presentation, \n",
    "                        date_ouverture, date_fermeture, website, pays, \n",
    "                        ville, latitude, longitude) \n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (row['id'], row['nom'], row['historique'], row['activites'], row['presentation'], \n",
    "          row['date_ouverture'], row['date_fermeture'], row['website'], row['pays'], \n",
    "          row['ville'], row['latitude'], row['longitude']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# N'oubliez pas de faire un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Insérer les données dans la table 'Question_Reponse'\n",
    "for i, row in df_selection3.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Question_Reponse (id_QR, question1, reponse1, question2, reponse2)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['id'], row['question1'], row['réponse1'], row['question2'], row['réponse2']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Insérer les données dans la table 'Responsable'\n",
    "for i, row in df_selection2.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Responsable (id_R, responsables, id_QReponse)\n",
    "    VALUES (?, ?, ?)\n",
    "    ''', (row['id'], row['responsables'], row['id']))\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "id_tenir = 1  # Initialiser un compteur pour id_tenir\n",
    "\n",
    "for i, row in df_selection1.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO tenir (id_tenir, id_espace, id_responsable)\n",
    "    VALUES (?, ?, ?)\n",
    "    ''', (id_tenir, row['id'], row['id']))  # Utiliser l'id_tenir incrémenté\n",
    "\n",
    "    id_tenir += 1  # Incrémenter l'ID pour la prochaine ligne\n",
    "\n",
    "    if i % 100 == 0:  # Effectuer un commit tous les 100 enregistrements\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "# Un dernier commit après la boucle\n",
    "conn.commit()\n",
    "\n",
    "# Sauvegarder (commit) les changements\n",
    "conn.commit()\n",
    "\n",
    "# Fermer la connexion à la base de données\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
